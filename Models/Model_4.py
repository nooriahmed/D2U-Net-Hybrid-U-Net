# -*- coding: utf-8 -*-
"""Model_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZmweSbQcWXeubMV3a9oqD5JD9SosYos2
"""

#Parameters, Memory, FLOPS Check

#https://github.com/manideep2510/melanoma_segmentation

#attach google drive
from google.colab import drive
drive.mount('/content/gdrive')


#Training

from keras.preprocessing import image
from keras.models import Model, Sequential
from keras.layers import Activation, Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, AveragePooling2D, MaxPooling2D, UpSampling2D, Input, Reshape
from keras.layers import Input, SeparableConv2D, GlobalAveragePooling2D, concatenate, Conv2DTranspose, Add, Activation, Multiply
from keras import backend as K
from keras.optimizers import Nadam, Adam, SGD
from keras.metrics import categorical_accuracy, binary_accuracy
#from keras_contrib.losses import jaccard
import tensorflow as tf
import numpy as np
import pandas as pd
import glob
import PIL
from PIL import Image
import matplotlib.pyplot as plt


def jaccard_distance(y_true, y_pred, smooth=100):
  y_true = K.cast(y_true, 'float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=[1, 2, 3])
  sum_ = K.sum(K.square(y_true), axis=[1, 2, 3]) + K.sum(K.square(y_pred), axis=[1, 2, 3])
  jac = (intersection + smooth) / (sum_ - intersection + smooth)
  return (1 - jac)

def iou(y_true, y_pred, smooth = 100):
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)
    jac = (intersection + smooth) / (sum_ - intersection + smooth)
    return jac

def focal_loss(y_true, y_pred, alpha=0.25, gamma=2):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())
    loss = -alpha * y_true * tf.pow(1 - y_pred, gamma) * tf.math.log(y_pred) - (1 - alpha) * (1 - y_true) * tf.pow(y_pred, gamma) * tf.math.log(1 - y_pred)
    return tf.reduce_mean(loss)

# To read the images in numerical order
import re
numbers = re.compile(r'(\d+)')
def numericalSort(value):
    parts = numbers.split(value)
    parts[1::2] = map(int, parts[1::2])
    return parts

import numpy as np
from PIL import Image
import glob

# Function to sort files numerically
def numericalSort(value):
    import re
    numbers = re.compile(r'(\d+)')
    parts = numbers.split(value)
    parts[1::2] = map(int, parts[1::2])
    return parts

# Define the target size for all images (e.g., 256x256)
target_size = (224, 224)

# Function to load, resize, and convert images to a consistent format
def load_images(filelist):
    return np.array([np.array(Image.open(fname).resize(target_size).convert('RGB')) for fname in filelist])

# Load and process all datasets
filelist_trainx = sorted(glob.glob('gdrive/MyDrive/Skin_224/trainx/*.jpg'), key=numericalSort)
X_train = load_images(filelist_trainx)

filelist_trainy = sorted(glob.glob('gdrive/MyDrive/Skin_224/trainy/*.png'), key=numericalSort)
Y_train = load_images(filelist_trainy)

filelist_testx = sorted(glob.glob('gdrive/MyDrive/Skin_224/testx/*.jpg'), key=numericalSort)
X_test = load_images(filelist_testx)

filelist_testy = sorted(glob.glob('gdrive/MyDrive/Skin_224/testy/*.png'), key=numericalSort)
Y_test = load_images(filelist_testy)

filelist_valx = sorted(glob.glob('gdrive/MyDrive/Skin_224/validationx/*.jpg'), key=numericalSort)
X_val = load_images(filelist_valx)

filelist_valy = sorted(glob.glob('gdrive/MyDrive/Skin_224/validationy/*.png'), key=numericalSort)
Y_val = load_images(filelist_valy)

import os

def count_images(folder_path, include_subdirectories=False):
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif'}  # Use a set for faster lookups
    image_count = 0

    with os.scandir(folder_path) as entries:
        for entry in entries:
            if entry.is_file() and os.path.splitext(entry.name)[1].lower() in image_extensions:
                image_count += 1
            elif include_subdirectories and entry.is_dir():
                image_count += count_images(entry.path, include_subdirectories=True)  # Recursively count images in subdirectories

    return image_count

# Provide the path to the folder containing the images
folder_path = 'gdrive/MyDrive/Skin_224/validationy'

# Call the function and print the number of images
num_images = count_images(folder_path, include_subdirectories=True)
print(f"The folder '{folder_path}' contains {num_images} images.")

#Dual paths at Encoder-Decoder, both ends
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow.keras.backend as K
import tensorflow as tf
from tensorflow.keras.layers import Input, SeparableConv2D, BatchNormalization, PReLU, MaxPooling2D, UpSampling2D, Concatenate, Dropout, Add, Conv2D, Conv2DTranspose
from tensorflow.keras.models import Model

# Function to align dataset sizes (removed)
#def align_dataset_sizes(X_train, Y_train, X_test, Y_test, X_val, Y_val):
#    min_length = min(len(X_train), len(Y_train), len(X_test), len(Y_test), len(X_val), len(Y_val))
#    return X_train[:min_length], Y_train[:min_length], X_test[:min_length], Y_test[:min_length], X_val[:min_length], Y_val[:min_length]

# Align the dataset sizes (removed)
#X_train, Y_train, X_test, Y_test, X_val, Y_val = align_dataset_sizes(X_train, Y_train, X_test, Y_test, X_val, Y_val)

# Convert target labels to single channel (grayscale) and normalize data
Y_train = np.mean(Y_train, axis=-1, keepdims=True)
Y_test = np.mean(Y_test, axis=-1, keepdims=True)
Y_val = np.mean(Y_val, axis=-1, keepdims=True)

# Ensure pixel values are in range [0, 1]
X_train = X_train / 255.0
X_test = X_test / 255.0
X_val = X_val / 255.0

# Debug print statements to check the shapes and contents of the arrays.
print(f"Shape of X_train: {X_train.shape}")
print(f"Shape of X_test: {X_test.shape}")
print(f"Shape of X_val: {X_val.shape}")
print(f"Shape of Y_train: {Y_train.shape}")
print(f"Shape of Y_test: {Y_test.shape}")
print(f"Shape of Y_val: {Y_val.shape}")

# Concatenate all data into a single array for splitting, check if arrays are empty
if X_val.size == 0:
    print("Warning: X_val is empty.")
    X_val = np.empty((0, 224, 224, 3), dtype=np.float64) # Creates an empty array with the correct dimensions, and dtype.
if Y_val.size == 0:
    print("Warning: Y_val is empty.")
    Y_val = np.empty((0, 224, 224, 1), dtype=np.float64)
if X_train.size == 0:
    print("Warning: X_train is empty.")
if Y_train.size == 0:
     print("Warning: Y_train is empty.")
if X_test.size == 0:
    print("Warning: X_test is empty.")
if Y_test.size == 0:
    print("Warning: Y_test is empty.")

X = np.concatenate((X_train, X_test, X_val), axis=0)
Y = np.concatenate((Y_train, Y_test, Y_val), axis=0)

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.3,
    height_shift_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    vertical_flip=True,
    brightness_range=[0.7, 1.3]
)

augmented_data = datagen.flow(X_train, Y_train, batch_size=32)

# Residual block with BatchNormalization, PReLU, and Dropout
def residual_block(x, filters, kernel_size=3, dropout_rate=0.3):
    res = layers.Conv2D(filters, kernel_size, padding='same', kernel_regularizer=keras.regularizers.l2(0.01))(x)
    res = layers.BatchNormalization()(res)  # Add Batch Normalization
    res = layers.PReLU()(res)
    res = layers.Conv2D(filters, kernel_size, padding='same', kernel_regularizer=keras.regularizers.l2(0.01))(res)
    res = layers.BatchNormalization()(res)  # Add Batch Normalization
    res = layers.Dropout(dropout_rate)(res)
    return layers.Add()([x, res])

# Channel and Spatial Attention
def channel_attention(input_feature, ratio=8):
    channel = input_feature.shape[-1]
    shared_layer_one = layers.Dense(channel // ratio, activation='relu')
    shared_layer_two = layers.Dense(channel)

    avg_pool = layers.GlobalAveragePooling2D()(input_feature)
    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)
    avg_pool = shared_layer_two(shared_layer_one(avg_pool))

    max_pool = layers.GlobalMaxPooling2D()(input_feature)
    max_pool = layers.Reshape((1, 1, channel))(max_pool)
    max_pool = shared_layer_two(shared_layer_one(max_pool))

    cbam_feature = layers.Add()([avg_pool, max_pool])
    cbam_feature = layers.Activation('sigmoid')(cbam_feature)

    return layers.multiply([input_feature, cbam_feature])

def spatial_attention(input_feature):
    kernel_size = 7
    avg_pool = layers.Lambda(lambda x: keras.backend.mean(x, axis=3, keepdims=True))(input_feature)
    max_pool = layers.Lambda(lambda x: keras.backend.max(x, axis=3, keepdims=True))(input_feature)
    concat = layers.Concatenate(axis=3)([avg_pool, max_pool])
    cbam_feature = layers.Conv2D(filters=1, kernel_size=kernel_size, strides=1, padding='same', activation='sigmoid')(concat)
    return layers.multiply([input_feature, cbam_feature])

# Define Dual Path U-Net with Attention, Residual Connections, PReLU, and Dropout
def dual_path_unet(input_shape=(224, 224, 3), dropout_rate=0.5):
    inputs = Input(input_shape)

    # Path 1: Global Features (Contextual Information)
    conv1_1 = SeparableConv2D(64, (3, 3), padding='same')(inputs)
    conv1_1 = BatchNormalization()(conv1_1)
    conv1_1 = PReLU()(conv1_1)
    conv1_1 = SeparableConv2D(64, (3, 3), padding='same')(conv1_1)
    conv1_1 = BatchNormalization()(conv1_1)
    conv1_1 = PReLU()(conv1_1)
    pool1_1 = MaxPooling2D(pool_size=(2, 2))(conv1_1)

    conv2_1 = SeparableConv2D(128, (3, 3), padding='same')(pool1_1)
    conv2_1 = BatchNormalization()(conv2_1)
    conv2_1 = PReLU()(conv2_1)
    conv2_1 = SeparableConv2D(128, (3, 3), padding='same')(conv2_1)
    conv2_1 = BatchNormalization()(conv2_1)
    conv2_1 = PReLU()(conv2_1)
    pool2_1 = MaxPooling2D(pool_size=(2, 2))(conv2_1)

    # Path 2: Local Features (Edges)
    conv1_2 = SeparableConv2D(64, (3, 3), padding='same')(inputs)
    conv1_2 = BatchNormalization()(conv1_2)
    conv1_2 = PReLU()(conv1_2)
    conv1_2 = SeparableConv2D(64, (3, 3), padding='same')(conv1_2)
    conv1_2 = BatchNormalization()(conv1_2)
    conv1_2 = PReLU()(conv1_2)
    pool1_2 = MaxPooling2D(pool_size=(2, 2))(conv1_2)

    conv2_2 = SeparableConv2D(128, (3, 3), padding='same')(pool1_2)
    conv2_2 = BatchNormalization()(conv2_2)
    conv2_2 = PReLU()(conv2_2)
    conv2_2 = SeparableConv2D(128, (3, 3), padding='same')(conv2_2)
    conv2_2 = BatchNormalization()(conv2_2)
    conv2_2 = PReLU()(conv2_2)
    pool2_2 = MaxPooling2D(pool_size=(2, 2))(conv2_2)

    # **U-Net Bottleneck**
    merged = Concatenate()([pool2_1, pool2_2])
    conv_b1 = SeparableConv2D(256, (3, 3), padding='same')(merged)
    conv_b1 = BatchNormalization()(conv_b1)
    conv_b1 = PReLU()(conv_b1)
    conv_b1 = Dropout(dropout_rate)(conv_b1)
    conv_b2 = SeparableConv2D(256, (3, 3), padding='same')(conv_b1)
    conv_b2 = BatchNormalization()(conv_b2)
    conv_b2 = PReLU()(conv_b2)

    up_b1 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv_b2) # Changed from UpSampling2D to Conv2DTranspose
    up_b1 = Concatenate()([up_b1, conv2_1, conv2_2])
    conv_b3 = SeparableConv2D(128, (3, 3), padding='same')(up_b1)
    conv_b3 = BatchNormalization()(conv_b3)
    conv_b3 = PReLU()(conv_b3)

    up_b2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv_b3) # Changed from UpSampling2D to Conv2DTranspose
    up_b2 = Concatenate()([up_b2, conv1_1, conv1_2])
    conv_b4 = SeparableConv2D(64, (3, 3), padding='same')(up_b2)
    conv_b4 = BatchNormalization()(conv_b4)
    conv_b4 = PReLU()(conv_b4)

    # Merge Bottleneck Output into Decoder Paths
    decoder_input = Concatenate()([conv_b4, conv1_1, conv1_2])

    # Decoder 1 (Global Features)
    up4_1 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(decoder_input) # Changed from UpSampling2D to Conv2DTranspose
    conv4_1 = SeparableConv2D(128, (3, 3), padding='same')(up4_1)
    conv4_1 = BatchNormalization()(conv4_1)
    conv4_1 = PReLU()(conv4_1)

    up5_1 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv4_1) # Changed from UpSampling2D to Conv2DTranspose
    conv5_1 = SeparableConv2D(64, (3, 3), padding='same')(up5_1)
    conv5_1 = BatchNormalization()(conv5_1)
    conv5_1 = PReLU()(conv5_1)

    # Decoder 2 (Local Features)
    up4_2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(decoder_input) # Changed from UpSampling2D to Conv2DTranspose
    conv4_2 = SeparableConv2D(128, (3, 3), padding='same')(up4_2)
    conv4_2 = BatchNormalization()(conv4_2)
    conv4_2 = PReLU()(conv4_2)

    up5_2 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv4_2) # Changed from UpSampling2D to Conv2DTranspose
    conv5_2 = SeparableConv2D(64, (3, 3), padding='same')(up5_2)
    conv5_2 = BatchNormalization()(conv5_2)
    conv5_2 = PReLU()(conv5_2)

    # Merge Outputs from Both Decoders
    merged_output = Concatenate()([conv5_1, conv5_2])
    outputs = Conv2D(1, (1, 1), activation='sigmoid')(merged_output)

    model = Model(inputs, outputs)
    return model


# Create the model
model = dual_path_unet((224, 224, 3))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Summary of the model
model.summary()

# Training with augmented data
history = model.fit(augmented_data, epochs=1, validation_data=(X_val, Y_val), verbose=1)

# Plotting training & validation loss and accuracy
def plot_history(history):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='train loss')
    plt.plot(history.history['val_loss'], label='val loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='train accuracy')
    plt.plot(history.history['val_accuracy'], label='val accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.show()

plot_history(history)

import tensorflow as tf
from tensorflow.keras.models import Model
import numpy as np

# Summary of the model
model.summary()

# Function to calculate FLOPs of the model
def get_flops(model):
    # Convert model to a concrete function
    concrete_func = tf.function(lambda x: model(x))
    concrete_func = concrete_func.get_concrete_function(
        [tf.TensorSpec([1] + list(model.input_shape[1:]), tf.float32)]
    )

    # Convert variables to constants using a session
    frozen_func = tf.compat.v1.graph_util.convert_variables_to_constants(
        sess=tf.compat.v1.Session(),
        input_graph_def=concrete_func.graph.as_graph_def(),
        output_node_names=[out.op.name for out in concrete_func.outputs]
    )

    # Calculate FLOPs using TensorFlow Profiler
    with tf.Graph().as_default() as graph:
        tf.import_graph_def(frozen_func, name='')
        flops = tf.compat.v1.profiler.profile(
            graph,
            options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()
        ).total_float_ops

    return flops

# Calculate FLOPs and print the result
flops = get_flops(model)
print(f"FLOPs: {flops}")

# Function to calculate the memory size of the model
def calculate_memory_size(model):
    # Using .shape instead of .get_shape()
    total_params = np.sum([np.prod(v.shape.as_list()) for v in model.trainable_weights])
    memory_size = total_params * 4 / (1024 ** 2)  # Convert to MB assuming 4 bytes per parameter (float32).
    return memory_size

# Calculate memory size and print the result
memory_size = calculate_memory_size(model)
print(f"Memory Size: {memory_size:.2f} MB")

import tensorflow as tf
import numpy as np

# Disable eager execution to work with TensorFlow 1.x graph-based operations
tf.compat.v1.disable_eager_execution()

# Function to calculate FLOPs of the model
def get_flops(model):
    input_shape = [1] + list(model.input_shape[1:])

    # Convert the model to a concrete function
    concrete_func = tf.function(lambda x: model(x))
    concrete_func = concrete_func.get_concrete_function(
        tf.TensorSpec(input_shape, tf.float32)
    )

    # Freeze the graph
    # Changed convert_variables_to_constants_v2 to convert_variables_to_constants
    frozen_func = tf.compat.v1.graph_util.convert_variables_to_constants(
        sess=tf.compat.v1.Session(), # Added a session here since it's required by convert_variables_to_constants
        input_graph_def=concrete_func.graph.as_graph_def(),
        output_node_names=[out.op.name for out in concrete_func.outputs]
    )

    # Get the frozen graph definition
    frozen_graph_def = frozen_func # Changed from frozen_func.graph.as_graph_def()

    # Create a new graph for FLOP calculation
    with tf.Graph().as_default() as graph:
        tf.import_graph_def(frozen_graph_def, name="")

        # Use TensorFlow Profiler to compute FLOPs
        # removed with tf.compat.v1.Session(graph=graph) as sess: context manager.
        flops = tf.compat.v1.profiler.profile(
            graph,
            options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()
        ).total_float_ops

    return flops

# Function to calculate the memory size of the model
def calculate_memory_size(model):
    total_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])
    memory_size = (total_params * 4) / (1024 ** 2)  # Convert bytes to MB (float32)
    return memory_size

# Load or define your model
input_tensor = tf.keras.Input(shape=(224, 224, 3))  # Ensure static input shape
model = tf.keras.applications.MobileNetV2(input_tensor=input_tensor, weights=None)

# Print model summary
model.summary()

# Calculate and display FLOPs
flops = get_flops(model)
print(f"FLOPs: {flops:,} FLOPs")

# Calculate and display memory size
memory_size = calculate_memory_size(model)
print(f"Memory Size: {memory_size:.2f} MB")

# Function to plot training & validation loss and accuracy
def plot_history(history):
    # Extract loss and accuracy for training and validation data
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    accuracy = history.history.get('accuracy')
    val_accuracy = history.history.get('val_accuracy')

    epochs = range(1, len(loss) + 1)

    # Plot training & validation loss
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, loss, 'bo', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot training & validation accuracy
    plt.subplot(1, 2, 2)
    if accuracy and val_accuracy:
        plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
        plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epochs')
        plt.ylabel('Accuracy')
        plt.legend()
    else:
        print("Accuracy metrics not available in history object.")

    plt.tight_layout()
    plt.show()

# Plot the training history
plot_history(history)

# Function to load and preprocess a single image
def preprocess_image(image):
    image = np.expand_dims(image, axis=0)
    return image

# Function to predict and visualize segmentation
def predict_and_visualize(model, x_test, y_test, index):
    image = x_test[index]
    ground_truth = Y_test[index]

    image_preprocessed = preprocess_image(image)
    prediction = model.predict(image_preprocessed)[0]

    plt.figure(figsize=(12, 6))

    plt.subplot(1, 3, 1)
    plt.title('Input Image')
    plt.imshow(image)

    plt.subplot(1, 3, 2)
    plt.title('Ground Truth')
    plt.imshow(ground_truth.squeeze(), cmap='gray')

    plt.subplot(1, 3, 3)
    plt.title('Prediction')
    plt.imshow(prediction.squeeze(), cmap='gray')

    plt.show()
# Example prediction and visualization
predict_and_visualize(model, X_test, Y_test, index=1)

import matplotlib.pyplot as plt

# Function to plot training & validation loss and accuracy
def plot_history(history):
    # Extract loss and accuracy for training and validation data
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    accuracy = history.history.get('accuracy')
    val_accuracy = history.history.get('val_accuracy')

    epochs = range(1, len(loss) + 1)

    # Plot training & validation loss
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, loss, 'bo', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot training & validation accuracy
    plt.subplot(1, 2, 2)
    if accuracy and val_accuracy:
        plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
        plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epochs')
        plt.ylabel('Accuracy')
        plt.legend()
    else:
        print("Accuracy metrics not available in history object.")

    plt.tight_layout()
    plt.show()

# Plot the history
plot_history(history)